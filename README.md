repo in env: C:\Users\User\source\repos\privacy-final

make new csv file in C:\Users\User\Documents\keywords

call the csv the letter that you're on, and then change the first variable in webscrape.py to reflect that

run the code before you visit noom
get a new card from privacy.com
get an email from temp-mail.org
run the scraper after you visit noom



websites:
  cnn.com
  nytimes.com
  dailymail.co.uk
  washingtonpost.com
  theatlantic.com
  huffpost.com
  wsj.com
 
 
google searches:
  clothes
 
